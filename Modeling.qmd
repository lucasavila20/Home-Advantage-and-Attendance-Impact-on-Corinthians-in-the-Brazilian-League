# Modeling

```{r include=FALSE, message=FALSE, warning=FALSE}
library(tidyverse)
```

```{r include=FALSE}
data <- read.csv("datacomoconheco.csv")
data <- data %>%
  mutate(result = recode(result,
  "V" = "V",
  "D" = "L",
  "E" = "D"))

data$result <- factor(data$result, levels = c("L", "D", "V"))

data[is.na(data$attendance), ]$attendance <- 38631.17

data$referee <- factor(data$referee)
data$time <- as.factor(data$time)

data <- data %>%
  mutate(day = recode(day,
  "seg" = "Mon",
  "ter" = "Tue",
  "qua" = "Wed",
  "qui" = "Thu",
  "sex" = "Fri",
  "sáb" = "Sat",
  "dom" = "Sun"))

data$day <- factor(data$day, levels = c("Mon", "Tue", "Wed", "Thu", "Fri", "Sat", "Sun"))
```



Basically, I want to test whether the outcome of the match—Victory, Defeat, or Draw—is independent of the location where the match was hosted—Home or Away. If they are independent, it would suggest that playing at home does not play any role in determining the winner. On the other hand, if they are not independent, it would indicate that playing at home provides some advantage to one of the teams.

To draw such conclusions, some statistical tests will be performed


## Assuming sample independence 

### Chi-squared test

Pandemic period

```{r cache = TRUE}
pandemic <- data %>% filter(attendance == 0) %>%
  with(table(venue, result)) 

chisq.test(as.matrix(pandemic))
```

```{r cache = TRUE}
non_pandemic <- data %>% 
  filter(attendance != 0) %>%
  with(table(venue, result)) 

chisq.test(as.matrix(non_pandemic))
```


Such an interesting result! Note that when the attendance was zero, playing at home does not provide any advantage (p-value = 0.8809). However, when there is an audience, the evidence is overwhelming (p-value close to $10^{-12}$), strongly indicating that the match location influences the result.



```{r cache = TRUE}  
table_venue <- table(data$venue, data$result)
chisq.test(as.matrix(table_venue))
```

Really low p-values indicates that, in general, venue and result are not independent, therefore, where the match is placed does influence the result.

Another way to verify that is


```{r cache = TRUE}  
library(gmodels)
t <- CrossTable(as.matrix(table_venue), resid = TRUE, sresid = TRUE, 
                asresid = TRUE, format = "SPSS", prop.r = FALSE, 
                prop.c = FALSE, prop.t = FALSE)
```

Many absolute values of residuals above 1.96, meaning that the difference between the observed and the expected data is statistically significant, therefore, the outcome of the match and the local where it was hosted is not independent 

### Log-linear model

```{r cache = TRUE, warning=FALSE, message=FALSE}
library(MASS)
df <- as.data.frame(table_venue)
reg <- loglm(Freq ~ Var1 + Var2, data = df)
reg
```
P-value was really small, which means that Var1 and Var2 are not independent (it doesn't fit into the multiple independence model), therefore, once again, playing home gives someone the advantage.


```{r cache = TRUE}
tab <- as.data.frame(table(data[,(colnames(data) %in% c("venue", "result", "time"))]))
reg <- loglm(Freq ~ time + venue + result, data = tab)
summary(reg)
extractAIC(reg)[2]
```

Testing first order interactions

```{r cache = TRUE}
reg2 <- loglm(Freq ~ time + venue + result + time:venue, data = tab)
summary(reg2)
extractAIC(reg2)[2]
```

```{r cache = TRUE}
reg3 <- loglm(Freq ~ time + venue + result + time:result, data = tab)
summary(reg3)
extractAIC(reg3)[2]
```

```{r cache = TRUE}
reg4 <- loglm(Freq ~ time + venue + result + venue:result, data = tab)
summary(reg4)
extractAIC(reg4)[2]
```

Once again we get to the same conclusion! With, and only with, the addition of the interaction between venue and result we have high p-values, meaning that those two factors are NOT independent.


### Multinomial regression

```{r cache = TRUE}
library(nnet)
```


```{r cache = TRUE}
multi_model <- multinom(result ~ venue + attendance + attendance:venue, data = data)

summary(multi_model)
```

```{r}
exp(summary(multi_model)$coeff)
```

Note that the coefficients for the interaction between venueHome and attendance is positive. That is a crucial piece of information to understand the meaning of this model.

```{r cache = TRUE}
summary_multi_model <- summary(multi_model)

coefs <- coef(summary_multi_model)
se <- summary_multi_model$standard.errors

z_values <- coefs / se
p_values <- 2 * (1 - pnorm(abs(z_values)))
p_values
```

That means that the public, venue, and their interaction are statistically significant to explain the outcome of the match, so I will keep all of them in the model.    

We can create a fake data just to show how it works in prediction

```{r cache = TRUE}
example_test <- data[1:4,c(5,11)]
example_test[1,] <- c("Home", 20)
example_test[2,] <- c("Away", 20)
example_test[3,] <- c("Home", 40000)
example_test[4,] <- c("Away", 40000)
example_test$venue <- factor(example_test$venue)
example_test$attendance <- as.numeric(example_test$attendance)

predictions <- predict(multi_model, 
                     newdata = example_test,
                     type = "probs")
head(predictions)
```

Notice that we created four different kinds of sample:

1) playing home with low audience
2) playing away with low audience
3) playing home with high audience
4) playing away with high audience


Playing home we have the highest probabilities of winning (48.52% and 60.64%), while playing away the lowest (31.42% and 26.59%). Notice that higher audience doesn't imply in higher probability of victory for Corinthians, since the interaction between venue and attendance is in the model. Playing with a higher audience at home rises up the probability of victory by diminishing the lose probability (and just a little bit the chances of drawing).

When playing away the effect is the complete opposite. Playing away with higher audiences increases the chances of defeat while diminishing significantly the winning and drawing probabilities.


## Assuming sample is not independent 

Of course the assumption of sample independence is highly questionable as we are talking about the same team on different rounds/seasons. Also, as we saw on EDA, the match outcome is high dependable on the opponent team, so it must also be taken into account. For that reason, we are gonna use non parametric test and mixed models to analyse the data.

### Non parametric test

So, basically I wanna test considering that, by each year and opponent, the sample is correlated. By that I mean that I want to compare the same teams (paired sample) on different moments (playing home and away), so I will use the McNemar test. 

#### Preparing the data

Lets separate only the clashes that happened both home and away on the same season 

<!-- #```{r cache = TRUE} -->
<!-- #first_half <- data -->
<!-- #first_half$round <- as.numeric(str_sub(first_half$round, -2, -1)) -->
<!-- #first_half <- first_half %>% -->
<!-- #  filter(round <= 19) -->
<!-- #``` -->



```{r cache = TRUE}
home <- data %>%
  filter(venue == 'Home') %>%
  filter(year < 2023)

away <- data %>%
  filter(venue == 'Visitante') %>%
  filter(year < 2023)
```


```{r cache = TRUE}
all.equal(home$Oponente, away$Oponente)
```

We wanna know if the proportion of victories changes when playing home in compared to when playing away, so lets turn the response variable into binary, 1 in case of victory and 0 otherwise. 

```{r cache = TRUE}
data2 <- data
data2$binary_response <- ifelse(data$result == "V", 1, 0)
```

And now lets transform the data in a way that we can see, by every year and opponent, how Corinthians did.  

```{r cache = TRUE}
transformed_data <-  data2 %>%
  group_by(Opponent, year) %>% 
  reframe(
    Home = binary_response[venue == "Home"],
    Away = binary_response[venue == "Away"]
  ) %>%
  na.omit() 

print(transformed_data %>% head())
```

```{r cache = TRUE}
table_mc <- table(Home = transformed_data$Home, Away = transformed_data$Away)
table_mc
```


The table show us that 53 times we did not win against a team when playing home and either when playing away. 19 times we did not win when playing home, but got the victory playing away. 67 times we won playing home, but draw or lost away. And 32 times we won both home and away. 

```{r cache = TRUE}
mcnemar.test(table_mc)
```

The test is telling us that the proportion of victory is really different when playing home than playing away. Just as expected!

### Mixed Modells

As said before, I want to control based on opponent and season.

```{r cache = TRUE, warning=FALSE}
library(lme4)

data2$venue <- as.factor(data2$venue)
data2$victory <- ifelse(data2$result == "V", 1, 0)
data2$draw_loss <- 1 - data2$victory

mixed_mod <- glmer(
  cbind(victory, draw_loss) ~ venue + attendance + venue:attendance + (1 | Opponent) + (1 | year), #result_binary
  family = binomial, 
  data = data2
)

summary(mixed_mod)
```

Note the fit warnings. Lets re scale the attendance variable to avoid errors.


```{r cache = TRUE, warning=FALSE}
data2$scaled_attendance <- (data2$attendance - mean(data2$attendance))/sd(data2$attendance)

mixed_mod <- glmer(
  cbind(victory, draw_loss) ~ venue + scaled_attendance + venue:scaled_attendance + (1 | Opponent) + (1 | year), #result_binary
  family = binomial(), 
  data = data2
)

summary(mixed_mod)
```

The model tell us the same as before. When playing home the coefficient for attendance is 0.2489 (that means that when playing home the bigger the audience, higher are the chances of winning), but when playing away it goes negative to -0.1031 (when playing away higher audiences means higher chances of not winning). 

When playing home with no audience the coefficient is 1.1930, but when playing away with no audience is -0.9441, and we can understand that by the same way done above. 

We can test this model the same way we did with the multinomial regression.


```{r cache = TRUE, warning=FALSE}
example_test2 <- data2[1:4,c(5,9, 17, 21)]
example_test2[1,] <- c("Home", "Grêmio", 2014, 20)
example_test2[2,] <- c("Away", "Grêmio", 2014, 20)
example_test2[3,] <- c("Home", "Grêmio", 2014, 40000)
example_test2[4,] <- c("Away", "Grêmio", 2014, 40000)
example_test2$scaled_attendance <- as.numeric(example_test2$scaled_attendance)
example_test2$scaled_attendance <- scale(example_test2$scaled_attendance)

predictions <- predict(mixed_mod, 
                     newdata = example_test2, 
                     type = "response"
                     )
predictions
```

And we can also visualize the model by using

```{r warning=FALSE, message=FALSE, cache=TRUE}
predictions <- predict(mixed_mod, type = "response", newdata = data2)
# Visualization
ggplot(data2, aes(x = attendance, y = predictions, color = as.factor(venue))) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  labs(title = "GLMM Predictions",
       x = "Attendance",
       y = "Predicted Probability",
       color = "venue")
```


Notice that the intercept for playing home is much higher than for playing away. Additionally, when playing home the slope is positive. Meanwhile, when playing away it is negative, endorsing the results previously obtained.   


This model has only one problem, but it's a major one: we notice that the attendance and the interaction between attendance and venue is not significant.


Now lets select variables based on their significance. Removing the interaction first:

```{r}
mixed_mod_no_interaction <- glmer(
  cbind(victory, draw_loss) ~ venue + scaled_attendance + (1 | Opponent) + (1 | year), #result_binary
  family = binomial(), 
  data = data2
)

summary(mixed_mod_no_interaction)
```
Removing the attendance (p-value of 0.893)

```{r}
mixed_mod_no_attendance <- glmer(
  cbind(victory, draw_loss) ~ venue + (1 | Opponent) + (1 | year), #result_binary
  family = binomial(), 
  data = data2
)

summary(mixed_mod_no_attendance)
```
Note that in this model all variables are significant, and both AIC and BIC are lower than the original model (with interaction), hence that is chosen to be the best model.

And now we shall test it

```{r cache = TRUE, warning=FALSE}
example_test3 <- data2[1:4,c(5,9, 17)]
example_test3[1,] <- c("Home", "Flamengo", 2014) # actually won at home
example_test3[2,] <- c("Away", "Flamengo", 2014) # and lost away
example_test3[3,] <- c("Home", "Cruzeiro", 2014) # won both home and away
example_test3[4,] <- c("Away", "Cruzeiro", 2014)
example_test3[5,] <- c("Home", "Coritiba", 2014) # didn't win both home and away
example_test3[6,] <- c("Away", "Coritiba", 2014)

predictions <- predict(mixed_mod_no_attendance, 
                     newdata = example_test3, 
                     type = "response"
                     )
predictions
```


```{r}
data2 %>% filter(year == 2014) %>% dplyr::select(date, Opponent, result) %>% arrange(Opponent) %>% filter(Opponent %in% c("Flamengo", "Coritiba", "Cruzeiro"))
```


```{r}
predictions <- predict(mixed_mod_no_attendance, 
                     newdata = data2, 
                     type = "response"
                     )
# Visualization
ggplot(data2, aes(x = venue, y = predictions)) +
  geom_point() +
  geom_smooth(method = "glm", method.args = list(family = "binomial")) +
  labs(title = "GLMM Predictions",
       x = "Predictor 1",
       y = "Predicted Probability")
```

A much more boring graph but shows what the model says: When playing home the winning probability is much higher than playing away.



